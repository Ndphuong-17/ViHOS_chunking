{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd D:\\Project\\Toolkit_for_Preprocessing_MXH\\ViHOS_chunking\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I3YIeVxjOnfY"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "# clear gpu memory using torch\n",
        "torch.cuda.empty_cache()\n",
        "# clear output\n",
        "clear_output()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y4KEsYU9Onff"
      },
      "outputs": [],
      "source": [
        "train_path = (r\"Data\\Chunking_data\\train.csv\")\n",
        "dev_path = (r\"Data\\Chunking_data\\dev.csv\")\n",
        "test_path = (r\"Data\\Chunking_data\\test.csv\")\n",
        "test_index = 50 # default None value\n",
        "batch_size = 64\n",
        "max_len = 64\n",
        "shuffle = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Kxoa7w9yOnfg"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    XLMRobertaModel,\n",
        "    AutoTokenizer\n",
        ")\n",
        "\n",
        "input_model = XLMRobertaModel.from_pretrained(\"vinai/phobert-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "input_model.resize_token_embeddings(len(tokenizer))\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w-Qyw31bOnfr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 46 samples\n",
            "Test set: 11 samples\n",
            "Development set: 15 samples\n"
          ]
        }
      ],
      "source": [
        "from Code.Dataset import split_path, create_dataloader\n",
        "\n",
        "if test_index != None and test_index > 3:\n",
        "    # Load the data\n",
        "    train_path, dev_path, test_path = split_path(test_path, test_index, train_path, dev_path, test_path)\n",
        "elif test_index != None: \n",
        "    print(\"Test index out of range. Please provide a valid interger index greater than 3.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns: Index(['index', 'Chunk', 'Tag', 'sentence_id', 'Spans'], dtype='object')\n",
            "Columns: Index(['index', 'Chunk', 'Tag', 'sentence_id', 'Spans'], dtype='object')\n",
            "Columns: Index(['index', 'Chunk', 'Tag', 'sentence_id', 'Spans'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = create_dataloader(train_path, batch_size=batch_size, tokenizer = tokenizer, max_len=max_len, shuffle=False)\n",
        "dev_dataloader = create_dataloader(dev_path, batch_size=batch_size, tokenizer = tokenizer, max_len=max_len, shuffle=False)\n",
        "test_dataloader = create_dataloader(test_path, batch_size=batch_size, tokenizer = tokenizer, max_len=max_len, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Code.Model import setup_model, MultiTaskModel, train, test\n",
        "\n",
        "# Set up the model and training components\n",
        "model, criterion_span, optimizer_spans, device, num_epochs = setup_model(\n",
        "    input_model=input_model,\n",
        "    model_class=MultiTaskModel,\n",
        "    lr=5e-6,\n",
        "    weight_decay=1e-5,\n",
        "    num_epochs=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.7193\n",
            "Validation Loss: 0.7762\n",
            "Span Macro F1-Score: 0.2103\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 0.6946\n",
            "Validation Loss: 0.7561\n",
            "Span Macro F1-Score: 0.2103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "train(\n",
        "    model=model,\n",
        "    train_dataloader=train_dataloader,\n",
        "    dev_dataloader=dev_dataloader,\n",
        "    criterion_span=criterion_span,\n",
        "    optimizer_spans=optimizer_spans,\n",
        "    device=device,\n",
        "    num_epochs=num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Span F1 Score: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Now you can call your train and test functions with the returned objects\n",
        "\n",
        "\n",
        "# Testing the model after training\n",
        "span_preds, span_targets = test(\n",
        "    model=model,\n",
        "    test_dataloader=test_dataloader,\n",
        "    device=device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to trained_model.pth\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "test_results = {\n",
        "    \"predictions\": span_preds.tolist(),\n",
        "    \"targets\": span_targets.tolist()\n",
        "}\n",
        "with open('result.json', 'w') as f:\n",
        "    json.dump(test_results, f, indent=4)\n",
        "    # print(f\"Test results saved to {args.output_json}\")\n",
        "\n",
        "    # Save the trained model\n",
        "    model_save_path =\"trained_model.pth\"\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f\"Model saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Training set: 46 samples\n",
            "Test set: 11 samples\n",
            "Development set: 15 samples\n",
            "Columns: Index(['index', 'Chunk', 'Tag', 'sentence_id', 'Spans'], dtype='object')\n",
            "Columns: Index(['index', 'Chunk', 'Tag', 'sentence_id', 'Spans'], dtype='object')\n",
            "Columns: Index(['index', 'Chunk', 'Tag', 'sentence_id', 'Spans'], dtype='object')\n",
            "Epoch: 1\n",
            "Training Loss: 0.6914\n",
            "Validation Loss: 0.8323\n",
            "Span Macro F1-Score: 0.1765\n",
            "Epoch: 2\n",
            "Training Loss: 0.7274\n",
            "Validation Loss: 0.8061\n",
            "Span Macro F1-Score: 0.1765\n",
            "Span F1 Score: 0.3750\n",
            "Test results saved to test_results.json\n",
            "Model saved to output\\trained_model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type roberta to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.\n",
            "C:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "C:\\Users\\ndp17\\.pyenv\\pyenv-win\\versions\\3.10.5\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "\n",
            "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Training: 100%|██████████| 1/1 [00:37<00:00, 37.61s/it]\n",
            "                                                       \n",
            "\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Validation: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
            "                                                         \n",
            "\n",
            "Training:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Training: 100%|██████████| 1/1 [00:31<00:00, 31.43s/it]\n",
            "                                                       \n",
            "\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Validation: 100%|██████████| 1/1 [00:03<00:00,  3.46s/it]\n",
            "                                                         \n",
            "\n",
            "Testing:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Testing: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
            "Testing: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n"
          ]
        }
      ],
      "source": [
        "!python main.py --train_path \"Data\\Chunking_data\\train.csv\" --dev_path \"Data\\Chunking_data\\dev.csv\" --test_path \"Data\\Chunking_data\\test.csv\" --batch_size 64 --max_len 128 --lr 5e-6 --num_epochs 2 --output_json \"test_results.json\" --output_dir \"output\" --test_index 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
